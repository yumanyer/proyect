connection handler failed
Traceback (most recent call last):
  File "C:\Users\manue\OneDrive\Escritorio\face-title\venv\lib\site-packages\websockets\asyncio\server.py", line 376, in conn_handler
    await self.handler(connection)
TypeError: handler() missing 1 required positional argument: 'path'

import cv2
import mediapipe as mp
import pygame

# LANDMARK
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# SONIDO
pygame.mixer.init()

# Cargar sonidos de notas 
sounds = [
    pygame.mixer.Sound("sounds/DO.wav"),   # Nota C (Do)
    pygame.mixer.Sound("sounds/RE.wav"),   # Nota D (Re)
    pygame.mixer.Sound("sounds/MI.wav"),   # Nota E (Mi)
    pygame.mixer.Sound("sounds/FA.wav"),   # Nota F (Fa)
    pygame.mixer.Sound("sounds/SOL.wav"),  # Nota G (Sol)
    pygame.mixer.Sound("sounds/LA.wav"),   # Nota A (La)
    pygame.mixer.Sound("sounds/SI.wav"),   # Nota B (Si)
    pygame.mixer.Sound("sounds/DO#.wav"),  # Nota C# (Do sostenido)
    pygame.mixer.Sound("sounds/RE#.wav"),  # Nota D# (Re sostenido)
    pygame.mixer.Sound("sounds/FA#.wav"),  # Nota F# (Fa sostenido)
]


# landmarks = la punta de los dedos de la mano
# finger_tip = nudillos de la mano
def dedo_abajo(landmarks, finger_tip, finger_mcp, is_thumb=False):
    if is_thumb:
        return landmarks[finger_tip].y > landmarks[3].y
    return landmarks[finger_tip].y > landmarks[finger_mcp].y



# cap = cv2.VideoCapture("rutadelvideo.mp3")
cap = cv2.VideoCapture(0)


# contex manager que nos ayuda a liberar recursos cuando se termina la aplicacion
with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=2) as hands:
    finger_state = [False] * 10
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break    

        frame = cv2.flip(frame, 1)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb_frame)

        hand_positions = []  # Lista para almacenar posiciones de las manos

        if results.multi_hand_landmarks and results.multi_handedness:
            for i, (hand_landmarks, handedness) in enumerate(zip(results.multi_hand_landmarks, results.multi_handedness)):
                x_coords = [lm.x for lm in hand_landmarks.landmark]
                hand_center = sum(x_coords) / len(x_coords)

                # Guardar la mano con su centro y landmarks
                hand_positions.append((hand_center, hand_landmarks, handedness.classification[0].label)) 

            # Ordenar manos por posiciÃ³n en pantalla (izquierda a derecha)
            hand_positions.sort(key=lambda x: x[0])

            for i, (center, hand_landmarks, hand_label) in enumerate(hand_positions):
                is_right_hand = hand_label == "Right"

                # Asignar IDs de mano
                if len(hand_positions) == 2:
                    hand_id = 6 if i == 0 else 1  # Izquierda: 6-10, Derecha: 1-5
                else:
                    hand_id = 1  # Si solo hay una, siempre 1-5

                finger_tips = [4, 8, 12, 16, 20]
                finger_mcp = [3, 5, 9, 13, 17]

                for j in range(5):# Iterar sobre los 5 dedos
                    h, w, _ = frame.shape
                    x_tip, y_tip = int(hand_landmarks.landmark[finger_tips[j]].x * w), int(hand_landmarks.landmark[finger_tips[j]].y * h)
                    x_mcp, y_mcp = int(hand_landmarks.landmark[finger_mcp[j]].x * w), int(hand_landmarks.landmark[finger_mcp[j]].y * h)

                    # ðŸŽ¨ LANDMARKS CLAVE EN ROJO
                    cv2.circle(frame, (x_tip, y_tip), 8, (0, 0, 255), -1)
                    cv2.circle(frame, (x_mcp, y_mcp), 8, (0, 255, 255), -1)

                    # Dibujar nÃºmero sobre la punta del dedo
                    number = hand_id + j
                    cv2.putText(frame, str(number), (x_tip - 10, y_tip - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                    # LOGICA DEL SONIDO
                    finger_index = number - 1
                    if dedo_abajo(hand_landmarks.landmark, finger_tips[j], finger_mcp[j]):
                        if not finger_state[finger_index]:
                            sounds[finger_index].play()
                            finger_state[finger_index] = True
                    else:
                        finger_state[finger_index] = False

                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

        cv2.imshow("Hand detection", frame)
        if cv2.waitKey(1) & 0xFF == 27: 
            break

cap.release()
cv2.destroyAllWindows()
